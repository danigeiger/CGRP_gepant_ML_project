{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Notebook 3: Optimizing of Selected Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/danigeiger/Desktop/Capstone/Analysis'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Pandas and Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ability to export model \n",
    "import joblib\n",
    "\n",
    "# Import fingerprint generator \n",
    "from padelpy import padeldescriptor\n",
    "\n",
    "# Import algorithms \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# Import Variance Threshold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "# Import Standard Scaler for target scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Import train-test split and grid search\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "# Import metrics for model evaluation\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "# Choose directory for CSV importing/exporting\n",
    "import os\n",
    "os.chdir(\"/Users/danigeiger/Desktop/Capstone/Analysis\")\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:  Review Top 20 Algorithms with Feature and Target Selections\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Feature Reduction</th>\n",
       "      <th>Target Variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>1.704929</td>\n",
       "      <td>0.828709</td>\n",
       "      <td>0.689196</td>\n",
       "      <td>0.040054</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>VarThres</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>1.715556</td>\n",
       "      <td>0.826127</td>\n",
       "      <td>0.432155</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>Full set</td>\n",
       "      <td>VarThres</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1.023296</td>\n",
       "      <td>0.825953</td>\n",
       "      <td>0.442141</td>\n",
       "      <td>0.693931</td>\n",
       "      <td>Small Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1.023738</td>\n",
       "      <td>0.822648</td>\n",
       "      <td>0.717056</td>\n",
       "      <td>0.685968</td>\n",
       "      <td>Small Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1.738724</td>\n",
       "      <td>0.820497</td>\n",
       "      <td>0.439096</td>\n",
       "      <td>0.299595</td>\n",
       "      <td>Full set</td>\n",
       "      <td>VarThres</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1.744667</td>\n",
       "      <td>0.819053</td>\n",
       "      <td>0.708355</td>\n",
       "      <td>0.295899</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>VarThres</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1.025351</td>\n",
       "      <td>0.816618</td>\n",
       "      <td>0.443815</td>\n",
       "      <td>0.687223</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1.025374</td>\n",
       "      <td>0.816454</td>\n",
       "      <td>0.713423</td>\n",
       "      <td>0.690787</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1.024913</td>\n",
       "      <td>0.813874</td>\n",
       "      <td>0.734580</td>\n",
       "      <td>0.255370</td>\n",
       "      <td>Small Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1.766036</td>\n",
       "      <td>0.813861</td>\n",
       "      <td>0.447139</td>\n",
       "      <td>0.123674</td>\n",
       "      <td>Full set</td>\n",
       "      <td>VarThres</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1.766555</td>\n",
       "      <td>0.813734</td>\n",
       "      <td>0.718690</td>\n",
       "      <td>0.122980</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>VarThres</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1.024955</td>\n",
       "      <td>0.813560</td>\n",
       "      <td>0.457612</td>\n",
       "      <td>0.254405</td>\n",
       "      <td>Small Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1.025914</td>\n",
       "      <td>0.812545</td>\n",
       "      <td>0.448716</td>\n",
       "      <td>0.267389</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1.026113</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.723734</td>\n",
       "      <td>0.263136</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>1.026205</td>\n",
       "      <td>0.810441</td>\n",
       "      <td>0.451227</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>1.026222</td>\n",
       "      <td>0.810322</td>\n",
       "      <td>0.725243</td>\n",
       "      <td>0.704168</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>1.025944</td>\n",
       "      <td>0.806169</td>\n",
       "      <td>0.749631</td>\n",
       "      <td>0.094129</td>\n",
       "      <td>Small Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>1.027079</td>\n",
       "      <td>0.804118</td>\n",
       "      <td>0.458691</td>\n",
       "      <td>0.067640</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>1.027079</td>\n",
       "      <td>0.804118</td>\n",
       "      <td>0.737008</td>\n",
       "      <td>0.073599</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unstandardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVR</td>\n",
       "      <td>1.027102</td>\n",
       "      <td>0.803952</td>\n",
       "      <td>0.458886</td>\n",
       "      <td>0.060679</td>\n",
       "      <td>Full Set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Adjusted R-Squared  R-Squared      RMSE  \\\n",
       "0                BaggingRegressor            1.704929   0.828709  0.689196   \n",
       "1                BaggingRegressor            1.715556   0.826127  0.432155   \n",
       "2           RandomForestRegressor            1.023296   0.825953  0.442141   \n",
       "3           RandomForestRegressor            1.023738   0.822648  0.717056   \n",
       "4           RandomForestRegressor            1.738724   0.820497  0.439096   \n",
       "5           RandomForestRegressor            1.744667   0.819053  0.708355   \n",
       "6           RandomForestRegressor            1.025351   0.816618  0.443815   \n",
       "7           RandomForestRegressor            1.025374   0.816454  0.713423   \n",
       "8       GradientBoostingRegressor            1.024913   0.813874  0.734580   \n",
       "9       GradientBoostingRegressor            1.766036   0.813861  0.447139   \n",
       "10      GradientBoostingRegressor            1.766555   0.813734  0.718690   \n",
       "11      GradientBoostingRegressor            1.024955   0.813560  0.457612   \n",
       "12      GradientBoostingRegressor            1.025914   0.812545  0.448716   \n",
       "13      GradientBoostingRegressor            1.026113   0.811111  0.723734   \n",
       "14  HistGradientBoostingRegressor            1.026205   0.810441  0.451227   \n",
       "15  HistGradientBoostingRegressor            1.026222   0.810322  0.725243   \n",
       "16               BaggingRegressor            1.025944   0.806169  0.749631   \n",
       "17                  LGBMRegressor            1.027079   0.804118  0.458691   \n",
       "18                  LGBMRegressor            1.027079   0.804118  0.737008   \n",
       "19                            SVR            1.027102   0.803952  0.458886   \n",
       "\n",
       "    Time Taken   Data Set Feature Reduction Target Variable  \n",
       "0     0.040054   Full Set          VarThres  Unstandardized  \n",
       "1     0.046716   Full set          VarThres    Standardized  \n",
       "2     0.693931  Small Set               NaN    Standardized  \n",
       "3     0.685968  Small Set               NaN  Unstandardized  \n",
       "4     0.299595   Full set          VarThres    Standardized  \n",
       "5     0.295899   Full Set          VarThres  Unstandardized  \n",
       "6     0.687223   Full Set               NaN    Standardized  \n",
       "7     0.690787   Full Set               NaN  Unstandardized  \n",
       "8     0.255370  Small Set               NaN  Unstandardized  \n",
       "9     0.123674   Full set          VarThres    Standardized  \n",
       "10    0.122980   Full Set          VarThres  Unstandardized  \n",
       "11    0.254405  Small Set               NaN    Standardized  \n",
       "12    0.267389   Full Set               NaN    Standardized  \n",
       "13    0.263136   Full Set               NaN  Unstandardized  \n",
       "14    0.690032   Full Set               NaN    Standardized  \n",
       "15    0.704168   Full Set               NaN  Unstandardized  \n",
       "16    0.094129  Small Set               NaN  Unstandardized  \n",
       "17    0.067640   Full Set               NaN    Standardized  \n",
       "18    0.073599   Full Set               NaN  Unstandardized  \n",
       "19    0.060679   Full Set               NaN    Standardized  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import top 20 best performing models\n",
    "top20 = pd.read_csv(\"lazy_predict_best_models.csv\")\n",
    "top20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Selection:\n",
    "##### Bagging Regressor, Random Forest Regressor, and Gradient Boosting Regressor on the Full Dataset with Variance Threshold Feature Reduction and Standardized Target Variables. \n",
    "\n",
    "##### These three algorithm-data pairings achieved the highest R-squared and adjusted R-squared values while maintaining the lowest root mean square error (RMSE). Additionally, the computation time for each algorithm was reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Feature Reduction</th>\n",
       "      <th>Target Variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>1.715556</td>\n",
       "      <td>0.826127</td>\n",
       "      <td>0.432155</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>Full set</td>\n",
       "      <td>VarThres</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1.738724</td>\n",
       "      <td>0.820497</td>\n",
       "      <td>0.439096</td>\n",
       "      <td>0.299595</td>\n",
       "      <td>Full set</td>\n",
       "      <td>VarThres</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1.766036</td>\n",
       "      <td>0.813861</td>\n",
       "      <td>0.447139</td>\n",
       "      <td>0.123674</td>\n",
       "      <td>Full set</td>\n",
       "      <td>VarThres</td>\n",
       "      <td>Standardized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Adjusted R-Squared  R-Squared      RMSE  \\\n",
       "1           BaggingRegressor            1.715556   0.826127  0.432155   \n",
       "4      RandomForestRegressor            1.738724   0.820497  0.439096   \n",
       "9  GradientBoostingRegressor            1.766036   0.813861  0.447139   \n",
       "\n",
       "   Time Taken  Data Set Feature Reduction Target Variable  \n",
       "1    0.046716  Full set          VarThres    Standardized  \n",
       "4    0.299595  Full set          VarThres    Standardized  \n",
       "9    0.123674  Full set          VarThres    Standardized  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_models = top20.loc[[1, 4, 9]]\n",
    "selected_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Repeat Data Preprocessing from Python Notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data sets\n",
    "full_set = pd.read_csv(\"Part4_IC50_cleansed.csv\")\n",
    "\n",
    "\n",
    "# Convert the standard_value column to a numeric type\n",
    "full_set['standard_value'] = pd.to_numeric(full_set['standard_value'], errors='coerce')\n",
    "\n",
    "# Convert values from nanomolar to molar \n",
    "full_set['standard_value'] = full_set['standard_value']*10**-9 \n",
    "\n",
    "# Take the negative log of the molar amount\n",
    "full_set['standard_value']= -np.log10(full_set['standard_value']) \n",
    "\n",
    "\n",
    "# Select the required columns for smi file for padel processing\n",
    "df_smiles_full_set = full_set[['canonical_smiles', 'molecule_chembl_id']]\n",
    "\n",
    "\n",
    "# Save to a .smi file (PaDEL format)\n",
    "df_smiles_full_set.to_csv('molecules_full.smi', sep='\\t', index=False, header=False)\n",
    "\n",
    "\n",
    "# Create fingerprints (features)\n",
    "padeldescriptor(\n",
    "    mol_dir='molecules_full.smi',          \n",
    "    d_file='fingerprints_full_output.csv', \n",
    "    fingerprints=True,                # binary data: where 1 represents the presence of some characteristic, and 0 means lacking that characteristic\n",
    "    retainorder=True,                 # you need this so we can tie labels/targets back to the correct row\n",
    ")\n",
    "\n",
    "# Import fingerprints / engineered features back in as dataframe\n",
    "fingerprints_full = pd.read_csv('fingerprints_full_output.csv')\n",
    "\n",
    "\n",
    "# Create a dataframe which includes targets, features and molecular identification\n",
    "fingerprints_with_targets_full_df = pd.concat([fingerprints_full, full_set['standard_value']], axis =1)\n",
    "\n",
    "\n",
    "# Export data for sharing and transparency\n",
    "fingerprints_with_targets_full_df.to_csv(\"fingerprints_with_targets_full.csv\")\n",
    "\n",
    "\n",
    "# Split full molecule data set into fingerprints (features) and standard values (targets)\n",
    "X_full_set = fingerprints_with_targets_full_df.drop(['Name', 'standard_value'], axis =1)\n",
    "y_full_set = fingerprints_with_targets_full_df['standard_value']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Apply Data Preprocessing Specific to Chosen Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Bernoulli Variance Formula for Binary Variance Threshold Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(threshold=0.8*(1-0.8)) \n",
    "X_full_set_reduced = selector.fit_transform(X_full_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set dimentions are : (430, 133)\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full_set_reduced, y_full_set, test_size = 0.2, random_state=42)\n",
    "\n",
    "print(f\"Data set dimentions are : {X_train_full.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Pandas DataFrames to NumPy Arrays for Efficient Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = np.array(X_train_full, dtype=np.float64)\n",
    "X_test_full = np.array(X_test_full, dtype=np.float64)\n",
    "y_train_full = np.array(y_train_full, dtype=np.float64)\n",
    "y_test_full = np.array(y_test_full, dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Standard Scaler to Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y_train_full = scaler.fit_transform(y_train_full.reshape(-1, 1)).flatten()\n",
    "y_test_full= scaler.transform(y_test_full.reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Optimizing Algorithms Through Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Bagging Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Default Parameters for Grid Search Optimization Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': None, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "bagging_reg = BaggingRegressor(random_state= 42)\n",
    "print(bagging_reg.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check RMSE and R-Squared Values on Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.4322\n",
      "Test R-Squared: 0.8261\n"
     ]
    }
   ],
   "source": [
    "bagging_reg.fit(X_train_full, y_train_full)\n",
    "y_pred = bagging_reg.predict(X_test_full)\n",
    "\n",
    "rmse_default = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_default = r2_score(y_test_full, y_pred)\n",
    "print(f\"Test RMSE: {rmse_default:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_default:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: According to scikit-learn documentation, if 'estimator' is set to None, the default is a decision tree with default decision tree parameters. \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Pass Grid Search for Bagging Regressor (864 combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:1315: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "1080 fits failed out of a total of 4320.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1080 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py\", line 389, in fit\n",
      "    return self._fit(X, y, max_samples=self.max_samples, **fit_params)\n",
      "  File \"/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py\", line 489, in _fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [-0.25297646 -0.25297646 -0.22650643 -0.22650643 -0.22851576 -0.22851576\n",
      " -0.23640743 -0.23640743 -0.21994571 -0.21994571 -0.21937387 -0.21937387\n",
      " -0.2448965  -0.2448965  -0.21862395 -0.21862395 -0.21705675 -0.21705675\n",
      " -0.25474205 -0.25474205 -0.22973546 -0.22973546 -0.2288902  -0.2288902\n",
      " -0.25098524 -0.25098524 -0.22623727 -0.22623727 -0.22430133 -0.22430133\n",
      " -0.23831455 -0.23831455 -0.21666949 -0.21666949 -0.21705085 -0.21705085\n",
      " -0.2627023  -0.2627023  -0.23409934 -0.23409934 -0.22826321 -0.22826321\n",
      " -0.25108797 -0.25108797 -0.22223352 -0.22223352 -0.22108531 -0.22108531\n",
      " -0.24091002 -0.24091002 -0.22105326 -0.22105326 -0.22001655 -0.22001655\n",
      " -0.40765119 -0.40765119 -0.37989213 -0.37989213 -0.3831147  -0.3831147\n",
      " -0.40318505 -0.40318505 -0.38171902 -0.38171902 -0.38177811 -0.38177811\n",
      " -0.39446313 -0.39446313 -0.38373167 -0.38373167 -0.38302643 -0.38302643\n",
      " -0.4036344  -0.4036344  -0.38224241 -0.38224241 -0.37866305 -0.37866305\n",
      " -0.39498126 -0.39498126 -0.38209992 -0.38209992 -0.38008807 -0.38008807\n",
      " -0.39646428 -0.39646428 -0.38612815 -0.38612815 -0.38421802 -0.38421802\n",
      " -0.39824741 -0.39824741 -0.38286685 -0.38286685 -0.37739615 -0.37739615\n",
      " -0.39576544 -0.39576544 -0.38080021 -0.38080021 -0.37922356 -0.37922356\n",
      " -0.38899749 -0.38899749 -0.38467615 -0.38467615 -0.3809056  -0.3809056\n",
      " -0.31257403 -0.31257403 -0.28299501 -0.28299501 -0.28208808 -0.28208808\n",
      " -0.30880904 -0.30880904 -0.27986184 -0.27986184 -0.27604326 -0.27604326\n",
      " -0.29936711 -0.29936711 -0.28043236 -0.28043236 -0.27482157 -0.27482157\n",
      " -0.30388334 -0.30388334 -0.28791568 -0.28791568 -0.28399348 -0.28399348\n",
      " -0.30028419 -0.30028419 -0.28274596 -0.28274596 -0.27804882 -0.27804882\n",
      " -0.3031758  -0.3031758  -0.27895043 -0.27895043 -0.27570877 -0.27570877\n",
      " -0.30018463 -0.30018463 -0.28303493 -0.28303493 -0.27650695 -0.27650695\n",
      " -0.29410622 -0.29410622 -0.2752354  -0.2752354  -0.2710465  -0.2710465\n",
      " -0.28572672 -0.28572672 -0.27702391 -0.27702391 -0.27102938 -0.27102938\n",
      " -0.30056563 -0.30056563 -0.2811822  -0.2811822  -0.28359518 -0.28359518\n",
      " -0.28560972 -0.28560972 -0.26495846 -0.26495846 -0.26412893 -0.26412893\n",
      " -0.26814712 -0.26814712 -0.2558771  -0.2558771  -0.25647692 -0.25647692\n",
      " -0.2970486  -0.2970486  -0.27676028 -0.27676028 -0.27686869 -0.27686869\n",
      " -0.28399456 -0.28399456 -0.267021   -0.267021   -0.26402261 -0.26402261\n",
      " -0.27044845 -0.27044845 -0.25802882 -0.25802882 -0.25749493 -0.25749493\n",
      " -0.2860445  -0.2860445  -0.27327907 -0.27327907 -0.27305478 -0.27305478\n",
      " -0.27248569 -0.27248569 -0.26111751 -0.26111751 -0.25851532 -0.25851532\n",
      " -0.26378808 -0.26378808 -0.25314536 -0.25314536 -0.25144939 -0.25144939\n",
      " -0.27481929 -0.27481929 -0.23536567 -0.23536567 -0.23030079 -0.23030079\n",
      " -0.24375496 -0.24375496 -0.22889293 -0.22889293 -0.22386482 -0.22386482\n",
      " -0.25462713 -0.25462713 -0.22439545 -0.22439545 -0.21954995 -0.21954995\n",
      " -0.26251762 -0.26251762 -0.23187667 -0.23187667 -0.22960012 -0.22960012\n",
      " -0.23890792 -0.23890792 -0.22279359 -0.22279359 -0.22374482 -0.22374482\n",
      " -0.25435516 -0.25435516 -0.22492241 -0.22492241 -0.22045378 -0.22045378\n",
      " -0.26476291 -0.26476291 -0.23431288 -0.23431288 -0.23243703 -0.23243703\n",
      " -0.25808306 -0.25808306 -0.22449112 -0.22449112 -0.22414259 -0.22414259\n",
      " -0.26442537 -0.26442537 -0.22811186 -0.22811186 -0.22618854 -0.22618854\n",
      " -0.40785994 -0.40785994 -0.38517284 -0.38517284 -0.38334628 -0.38334628\n",
      " -0.38732687 -0.38732687 -0.37985248 -0.37985248 -0.38089942 -0.38089942\n",
      " -0.39963066 -0.39963066 -0.38460292 -0.38460292 -0.38175119 -0.38175119\n",
      " -0.40533919 -0.40533919 -0.38309159 -0.38309159 -0.37891709 -0.37891709\n",
      " -0.3865949  -0.3865949  -0.37849853 -0.37849853 -0.37553407 -0.37553407\n",
      " -0.39533449 -0.39533449 -0.38294506 -0.38294506 -0.3780752  -0.3780752\n",
      " -0.39668866 -0.39668866 -0.37921364 -0.37921364 -0.37476263 -0.37476263\n",
      " -0.39578411 -0.39578411 -0.380821   -0.380821   -0.37769944 -0.37769944\n",
      " -0.395762   -0.395762   -0.37672161 -0.37672161 -0.37540566 -0.37540566\n",
      " -0.30817222 -0.30817222 -0.2838271  -0.2838271  -0.28330386 -0.28330386\n",
      " -0.28715073 -0.28715073 -0.27694962 -0.27694962 -0.27633541 -0.27633541\n",
      " -0.29571336 -0.29571336 -0.27894618 -0.27894618 -0.27417298 -0.27417298\n",
      " -0.30774058 -0.30774058 -0.27902297 -0.27902297 -0.27799604 -0.27799604\n",
      " -0.2822778  -0.2822778  -0.27337082 -0.27337082 -0.27125568 -0.27125568\n",
      " -0.29148959 -0.29148959 -0.27403705 -0.27403705 -0.27036222 -0.27036222\n",
      " -0.29940868 -0.29940868 -0.2734267  -0.2734267  -0.27018077 -0.27018077\n",
      " -0.29756892 -0.29756892 -0.27434135 -0.27434135 -0.26890429 -0.26890429\n",
      " -0.29734569 -0.29734569 -0.26816427 -0.26816427 -0.26592737 -0.26592737\n",
      " -0.30403021 -0.30403021 -0.27610238 -0.27610238 -0.27630676 -0.27630676\n",
      " -0.27860954 -0.27860954 -0.26404182 -0.26404182 -0.26400903 -0.26400903\n",
      " -0.26507405 -0.26507405 -0.25657833 -0.25657833 -0.25590282 -0.25590282\n",
      " -0.30233687 -0.30233687 -0.27420929 -0.27420929 -0.27321815 -0.27321815\n",
      " -0.27243783 -0.27243783 -0.26316216 -0.26316216 -0.259774   -0.259774\n",
      " -0.26841649 -0.26841649 -0.25643737 -0.25643737 -0.254318   -0.254318\n",
      " -0.29661973 -0.29661973 -0.27553836 -0.27553836 -0.27246425 -0.27246425\n",
      " -0.29061086 -0.29061086 -0.26441795 -0.26441795 -0.26418067 -0.26418067\n",
      " -0.28192146 -0.28192146 -0.25208056 -0.25208056 -0.25096951 -0.25096951\n",
      "         nan -0.25389465         nan -0.22378754         nan -0.22432945\n",
      "         nan -0.22870989         nan -0.22283059         nan -0.22093885\n",
      "         nan -0.24068216         nan -0.22982544         nan -0.22930611\n",
      "         nan -0.24040399         nan -0.2273983          nan -0.22231879\n",
      "         nan -0.25308027         nan -0.2285401          nan -0.22530401\n",
      "         nan -0.2556121          nan -0.23864281         nan -0.23553915\n",
      "         nan -0.24373946         nan -0.22602923         nan -0.22496535\n",
      "         nan -0.25081961         nan -0.23199321         nan -0.23085627\n",
      "         nan -0.26523792         nan -0.24290881         nan -0.24474687\n",
      "         nan -0.40166102         nan -0.38707022         nan -0.3892224\n",
      "         nan -0.40125277         nan -0.39654132         nan -0.39563512\n",
      "         nan -0.40209808         nan -0.40486702         nan -0.40728287\n",
      "         nan -0.40674041         nan -0.38796108         nan -0.38902576\n",
      "         nan -0.40388999         nan -0.3961305          nan -0.39690777\n",
      "         nan -0.42110082         nan -0.41375336         nan -0.41639543\n",
      "         nan -0.3896977          nan -0.38421511         nan -0.38641702\n",
      "         nan -0.40209061         nan -0.40121389         nan -0.40092102\n",
      "         nan -0.4230818          nan -0.42390146         nan -0.42832597\n",
      "         nan -0.30147959         nan -0.27860837         nan -0.28145831\n",
      "         nan -0.28677759         nan -0.28005284         nan -0.27909679\n",
      "         nan -0.28687727         nan -0.28299431         nan -0.28340099\n",
      "         nan -0.28816703         nan -0.27446723         nan -0.27550509\n",
      "         nan -0.29421778         nan -0.27733037         nan -0.27754273\n",
      "         nan -0.30186658         nan -0.28759724         nan -0.28863066\n",
      "         nan -0.27462055         nan -0.26934675         nan -0.27192885\n",
      "         nan -0.28924474         nan -0.27824424         nan -0.27971724\n",
      "         nan -0.30856796         nan -0.29627774         nan -0.29932675\n",
      "         nan -0.28141042         nan -0.26668872         nan -0.26620527\n",
      "         nan -0.25658345         nan -0.25618278         nan -0.25409146\n",
      "         nan -0.25840346         nan -0.2453594          nan -0.24802928\n",
      "         nan -0.27299485         nan -0.26154524         nan -0.259651\n",
      "         nan -0.27243883         nan -0.25164542         nan -0.25234684\n",
      "         nan -0.25966043         nan -0.25110682         nan -0.25303691\n",
      "         nan -0.27047553         nan -0.25989747         nan -0.26356652\n",
      "         nan -0.2653429          nan -0.24950125         nan -0.25411328\n",
      "         nan -0.26624259         nan -0.25782555         nan -0.26104342\n",
      "         nan -0.23455713         nan -0.22711172         nan -0.2219969\n",
      "         nan -0.24840714         nan -0.22556215         nan -0.22258094\n",
      "         nan -0.25374418         nan -0.24216651         nan -0.23848582\n",
      "         nan -0.24432369         nan -0.23271619         nan -0.22661562\n",
      "         nan -0.25119049         nan -0.23062476         nan -0.22928748\n",
      "         nan -0.27447028         nan -0.26325128         nan -0.26059326\n",
      "         nan -0.24444014         nan -0.22606403         nan -0.22807988\n",
      "         nan -0.25751294         nan -0.24055621         nan -0.23824436\n",
      "         nan -0.31457007         nan -0.31239878         nan -0.31140267\n",
      "         nan -0.39273487         nan -0.38773477         nan -0.38561465\n",
      "         nan -0.40598448         nan -0.39853472         nan -0.39843537\n",
      "         nan -0.42834512         nan -0.42551243         nan -0.42640637\n",
      "         nan -0.39200038         nan -0.38839287         nan -0.38538266\n",
      "         nan -0.41107477         nan -0.40714122         nan -0.40463787\n",
      "         nan -0.45593368         nan -0.44736169         nan -0.44709838\n",
      "         nan -0.40106673         nan -0.38697706         nan -0.38670497\n",
      "         nan -0.41805782         nan -0.41528127         nan -0.41078091\n",
      "         nan -0.46955474         nan -0.46958131         nan -0.46966034\n",
      "         nan -0.29554396         nan -0.28178885         nan -0.2772773\n",
      "         nan -0.29178178         nan -0.27882259         nan -0.27841432\n",
      "         nan -0.30026448         nan -0.29563842         nan -0.29573224\n",
      "         nan -0.28825553         nan -0.27851086         nan -0.27449062\n",
      "         nan -0.29905018         nan -0.28309149         nan -0.28063286\n",
      "         nan -0.3270688          nan -0.32042248         nan -0.32154667\n",
      "         nan -0.28559706         nan -0.27262345         nan -0.27320497\n",
      "         nan -0.29430013         nan -0.288462           nan -0.2876172\n",
      "         nan -0.37239232         nan -0.37229594         nan -0.37257043\n",
      "         nan -0.26326301         nan -0.26109455         nan -0.25893838\n",
      "         nan -0.26640807         nan -0.25216493         nan -0.25089291\n",
      "         nan -0.27652148         nan -0.2603412          nan -0.25733525\n",
      "         nan -0.26786919         nan -0.2615964          nan -0.2575204\n",
      "         nan -0.27154179         nan -0.25589295         nan -0.25257376\n",
      "         nan -0.2909712          nan -0.2909832          nan -0.28689493\n",
      "         nan -0.27491231         nan -0.25711508         nan -0.25810006\n",
      "         nan -0.26861661         nan -0.25761117         nan -0.25652813\n",
      "         nan -0.35220498         nan -0.35120478         nan -0.35194032]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid options\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False], \n",
    "    'max_features': [0.6, 0.8, 1.0], \n",
    "    'max_samples': [0.6, 0.8, 1.0], \n",
    "    'n_estimators': [10, 50, 100], \n",
    "    'oob_score': [True, False], \n",
    "    'warm_start': [False],  \n",
    "    'estimator': [\n",
    "        DecisionTreeRegressor(max_depth=None, min_samples_split=2, min_samples_leaf=1),  # Tree with default parameters\n",
    "        DecisionTreeRegressor(max_depth=3, min_samples_split=2, min_samples_leaf=1),\n",
    "        DecisionTreeRegressor(max_depth=5, min_samples_split=4, min_samples_leaf=2),\n",
    "        DecisionTreeRegressor(max_depth=10, min_samples_split=5, min_samples_leaf=4),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validatoin\n",
    "grid_search = GridSearchCV(bagging_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4, verbose=0)\n",
    "\n",
    "# Fit Grid Search to the training data\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Apply best parameters to Bagging Regressor\n",
    "bagging_reg = BaggingRegressor(**grid_search.best_params_, random_state=42)\n",
    "bagging_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions from test features\n",
    "y_pred = bagging_reg.predict(X_test_full)\n",
    "\n",
    "# Calculate model evaluation metrics\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_grid = r2_score(y_test_full, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters and Performance from First Grid Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': True, 'bootstrap_features': True, 'estimator': DecisionTreeRegressor(), 'max_features': 0.8, 'max_samples': 1.0, 'n_estimators': 50, 'oob_score': True, 'warm_start': False}\n",
      "Test RMSE: 0.4333\n",
      "Test R-Squared: 0.8252\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Test RMSE: {rmse_grid:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Differences in Metrics from the Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Difference: -0.001119\n",
      "R-Squared Difference: -0.000902\n"
     ]
    }
   ],
   "source": [
    "diff_rmse = rmse_default - rmse_grid\n",
    "diff_r2 =  r2_grid - r2_default\n",
    "\n",
    "print(f\"RMSE Difference: {diff_rmse:.6f}\")\n",
    "print(f\"R-Squared Difference: {diff_r2:.6f}\")\n",
    "\n",
    "#Note: A positive value indicates that Grid Search has improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Pass Grid Search for Bagging Regressor (30 Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid options\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'bootstrap_features': [True],\n",
    "    'max_features': [0.75, 0.80, 0.85], \n",
    "    'max_samples': [0.95, 1.0], \n",
    "    'n_estimators': [30, 40, 50, 60, 70],\n",
    "    'estimator': [DecisionTreeRegressor(max_depth=None, min_samples_split=2, min_samples_leaf=1)],\n",
    "    'oob_score': [True],\n",
    "    'warm_start': [False]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validatoin\n",
    "grid_search = GridSearchCV(bagging_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4, verbose=0)\n",
    "\n",
    "# Fit Grid Search to the training data\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Apply best parameters to Bagging Regressor\n",
    "bagging_reg = BaggingRegressor(**grid_search.best_params_, random_state=42)\n",
    "bagging_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions from test features\n",
    "y_pred = bagging_reg.predict(X_test_full)\n",
    "\n",
    "# calculate model evaluation metrics\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_grid = r2_score(y_test_full, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters and Performance from Second Grid Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': True, 'bootstrap_features': True, 'estimator': DecisionTreeRegressor(), 'max_features': 0.85, 'max_samples': 1.0, 'n_estimators': 30, 'oob_score': True, 'warm_start': False}\n",
      "Test RMSE: 0.4439\n",
      "Test R-Squared: 0.8165\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Test RMSE: {rmse_grid:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Differences in Metrics from the Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Difference: -0.011763\n",
      "R-Squared Difference: -0.009594\n"
     ]
    }
   ],
   "source": [
    "diff_rmse = rmse_default - rmse_grid\n",
    "diff_r2 =  r2_grid - r2_default\n",
    "\n",
    "print(f\"RMSE Difference: {diff_rmse:.6f}\")\n",
    "print(f\"R-Squared Difference: {diff_r2:.6f}\")\n",
    "\n",
    "#Note: A positive value indicates that Grid Search has improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Pass Grid Search for Bagging Regressor (30 Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid options\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'bootstrap_features': [True],\n",
    "    'max_features': [0.78, 0.80, 0.82], \n",
    "    'max_samples': [0.95, 1.0], \n",
    "    'n_estimators': [45, 47, 50, 53, 55],\n",
    "    'estimator': [DecisionTreeRegressor(max_depth=None, min_samples_split=2, min_samples_leaf=1)],\n",
    "    'oob_score': [True],\n",
    "    'warm_start': [False]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validatoin\n",
    "grid_search = GridSearchCV(bagging_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4, verbose=0)\n",
    "\n",
    "# Fit Grid Search to the training data\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Apply best parameters to Bagging Regressor\n",
    "bagging_reg = BaggingRegressor(**grid_search.best_params_, random_state=42)\n",
    "bagging_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions from test features\n",
    "y_pred = bagging_reg.predict(X_test_full)\n",
    "\n",
    "# Calculate model evaluation metrics\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_grid = r2_score(y_test_full, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters and Performance from Third Grid Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': True, 'bootstrap_features': True, 'estimator': DecisionTreeRegressor(), 'max_features': 0.8, 'max_samples': 1.0, 'n_estimators': 53, 'oob_score': True, 'warm_start': False}\n",
      "Test RMSE: 0.4326\n",
      "Test R-Squared: 0.8258\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Test RMSE: {rmse_grid:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Differences in Metrics from the Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Difference: -0.000445\n",
      "R-Squared Difference: -0.000359\n"
     ]
    }
   ],
   "source": [
    "diff_rmse = rmse_default - rmse_grid\n",
    "diff_r2 =  r2_grid - r2_default\n",
    "\n",
    "print(f\"RMSE Difference: {diff_rmse:.6f}\")\n",
    "print(f\"R-Squared Difference: {diff_r2:.6f}\")\n",
    "\n",
    "#Note: A positive value indicates that Grid Search has improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Validation RMSE to Test Set RMSE for Model Fit Assessment \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Grid Search returns negative mean squared error as its scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average validation RMSE is 0.4643 units and the test RMSE is 0.4326 units.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The average validation RMSE is {np.sqrt(abs(grid_search.best_score_)):.4f} units and the test RMSE is {rmse_grid:.4f} units.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Despite a slight decrease of 0.000445 in the R-squared value, cross-validation results indicate strong model performance. The small difference between the test RMSE (0.4326) and the average validation RMSE (0.4643) suggests that the model generalizes well.\n",
    "\n",
    "#### We will use the final Grid Search parameters for our Bagging Regressor model. Although the trees have no maximum depth, the minimal difference between validation and test RMSE confirms that there is no significant overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Bagging Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingRegressor(bootstrap_features=True, estimator=DecisionTreeRegressor(),\n",
       "                 max_features=0.8, n_estimators=53, oob_score=True,\n",
       "                 random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BaggingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.BaggingRegressor.html\">?<span>Documentation for BaggingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>BaggingRegressor(bootstrap_features=True, estimator=DecisionTreeRegressor(),\n",
       "                 max_features=0.8, n_estimators=53, oob_score=True,\n",
       "                 random_state=42)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: DecisionTreeRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingRegressor(bootstrap_features=True, estimator=DecisionTreeRegressor(),\n",
       "                 max_features=0.8, n_estimators=53, oob_score=True,\n",
       "                 random_state=42)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_reg = BaggingRegressor(**grid_search.best_params_, random_state=42)\n",
    "bagging_reg.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Performance Metrics in a DataFrame for Comparison of All Models at the End) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model   RMSE  R-Squared\n",
       "0  Bagging Regressor  0.433      0.826"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"Bagging Regressor\"\n",
    "results1 = pd.DataFrame([[model_name, round(rmse_grid,3), round(r2_grid,3)]], columns=[\"Model\", \"RMSE\", \"R-Squared\"])\n",
    "results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Default Parameters for Grid Search Optimization Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(random_state= 42)\n",
    "print(rf_reg.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check RMSE and R-Squared Values on Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.4391\n",
      "Test R-Squared: 0.8205\n"
     ]
    }
   ],
   "source": [
    "rf_reg.fit(X_train_full, y_train_full)\n",
    "y_pred = rf_reg.predict(X_test_full)\n",
    "\n",
    "rmse_default = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_default = r2_score(y_test_full, y_pred)\n",
    "print(f\"Test RMSE: {rmse_default:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_default:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First pass Grid Search for Random Forest Regressor (576 Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "720 fits failed out of a total of 2880.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 448, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/danigeiger/opt/anaconda3/envs/Module_2_670/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [-0.22776861 -0.22776861 -0.22649505 -0.22649505 -0.22261222 -0.22261222\n",
      " -0.22026544 -0.22026544 -0.24285651 -0.24285651 -0.23749283 -0.23749283\n",
      " -0.24285651 -0.24285651 -0.23749283 -0.23749283 -0.26609036 -0.26609036\n",
      " -0.26295088 -0.26295088 -0.26609036 -0.26609036 -0.26295088 -0.26295088\n",
      " -0.29803    -0.29803    -0.29523139 -0.29523139 -0.29792411 -0.29792411\n",
      " -0.29628831 -0.29628831 -0.30426055 -0.30426055 -0.30288373 -0.30288373\n",
      " -0.30426055 -0.30426055 -0.30288373 -0.30288373 -0.31488047 -0.31488047\n",
      " -0.31195202 -0.31195202 -0.31488047 -0.31488047 -0.31195202 -0.31195202\n",
      " -0.2241641  -0.2241641  -0.22223606 -0.22223606 -0.22555856 -0.22555856\n",
      " -0.22310196 -0.22310196 -0.24173428 -0.24173428 -0.23865293 -0.23865293\n",
      " -0.24173428 -0.24173428 -0.23865293 -0.23865293 -0.26248448 -0.26248448\n",
      " -0.26211517 -0.26211517 -0.26248448 -0.26248448 -0.26211517 -0.26211517\n",
      " -0.29492887 -0.29492887 -0.29484937 -0.29484937 -0.29523664 -0.29523664\n",
      " -0.29513963 -0.29513963 -0.30062574 -0.30062574 -0.30123904 -0.30123904\n",
      " -0.30062574 -0.30062574 -0.30123904 -0.30123904 -0.31174078 -0.31174078\n",
      " -0.31106989 -0.31106989 -0.31174078 -0.31174078 -0.31106989 -0.31106989\n",
      " -0.22921621 -0.22921621 -0.22186864 -0.22186864 -0.222844   -0.222844\n",
      " -0.22196483 -0.22196483 -0.2433182  -0.2433182  -0.23788092 -0.23788092\n",
      " -0.2433182  -0.2433182  -0.23788092 -0.23788092 -0.26612081 -0.26612081\n",
      " -0.26318164 -0.26318164 -0.26612081 -0.26612081 -0.26318164 -0.26318164\n",
      " -0.29803    -0.29803    -0.29526377 -0.29526377 -0.29792411 -0.29792411\n",
      " -0.29628831 -0.29628831 -0.30426055 -0.30426055 -0.30288373 -0.30288373\n",
      " -0.30426055 -0.30426055 -0.30288373 -0.30288373 -0.31488047 -0.31488047\n",
      " -0.31195202 -0.31195202 -0.31488047 -0.31488047 -0.31195202 -0.31195202\n",
      " -0.22486965 -0.22486965 -0.22190141 -0.22190141 -0.22466642 -0.22466642\n",
      " -0.22187374 -0.22187374 -0.24188791 -0.24188791 -0.23873768 -0.23873768\n",
      " -0.24188791 -0.24188791 -0.23873768 -0.23873768 -0.26253035 -0.26253035\n",
      " -0.26215613 -0.26215613 -0.26253035 -0.26253035 -0.26215613 -0.26215613\n",
      " -0.29492887 -0.29492887 -0.29484937 -0.29484937 -0.29523664 -0.29523664\n",
      " -0.29513963 -0.29513963 -0.30062574 -0.30062574 -0.30123904 -0.30123904\n",
      " -0.30062574 -0.30062574 -0.30123904 -0.30123904 -0.31174078 -0.31174078\n",
      " -0.31106989 -0.31106989 -0.31174078 -0.31174078 -0.31106989 -0.31106989\n",
      " -0.22776861 -0.22776861 -0.22649505 -0.22649505 -0.22261222 -0.22261222\n",
      " -0.22026544 -0.22026544 -0.24285651 -0.24285651 -0.23749283 -0.23749283\n",
      " -0.24285651 -0.24285651 -0.23749283 -0.23749283 -0.26609036 -0.26609036\n",
      " -0.26295088 -0.26295088 -0.26609036 -0.26609036 -0.26295088 -0.26295088\n",
      " -0.29803    -0.29803    -0.29523139 -0.29523139 -0.29792411 -0.29792411\n",
      " -0.29628831 -0.29628831 -0.30426055 -0.30426055 -0.30288373 -0.30288373\n",
      " -0.30426055 -0.30426055 -0.30288373 -0.30288373 -0.31488047 -0.31488047\n",
      " -0.31195202 -0.31195202 -0.31488047 -0.31488047 -0.31195202 -0.31195202\n",
      " -0.2241641  -0.2241641  -0.22226605 -0.22226605 -0.22555856 -0.22555856\n",
      " -0.22310196 -0.22310196 -0.24173428 -0.24173428 -0.23865293 -0.23865293\n",
      " -0.24173428 -0.24173428 -0.23865293 -0.23865293 -0.26248448 -0.26248448\n",
      " -0.26211517 -0.26211517 -0.26248448 -0.26248448 -0.26211517 -0.26211517\n",
      " -0.29492887 -0.29492887 -0.29484937 -0.29484937 -0.29523664 -0.29523664\n",
      " -0.29513963 -0.29513963 -0.30062574 -0.30062574 -0.30123904 -0.30123904\n",
      " -0.30062574 -0.30062574 -0.30123904 -0.30123904 -0.31174078 -0.31174078\n",
      " -0.31106989 -0.31106989 -0.31174078 -0.31174078 -0.31106989 -0.31106989\n",
      " -0.26576813         nan -0.2683807          nan -0.27215969         nan\n",
      " -0.26816926         nan -0.27554911         nan -0.27336357         nan\n",
      " -0.27554911         nan -0.27336357         nan -0.29934129         nan\n",
      " -0.29816267         nan -0.29934129         nan -0.29816267         nan\n",
      " -0.36623297         nan -0.36376161         nan -0.36425156         nan\n",
      " -0.36424497         nan -0.36619958         nan -0.36809207         nan\n",
      " -0.36619958         nan -0.36809207         nan -0.37694267         nan\n",
      " -0.37576428         nan -0.37694267         nan -0.37576428         nan\n",
      " -0.31252924         nan -0.31256271         nan -0.31964997         nan\n",
      " -0.31802327         nan -0.32957624         nan -0.32911672         nan\n",
      " -0.32957624         nan -0.32911672         nan -0.34315929         nan\n",
      " -0.34275167         nan -0.34315929         nan -0.34275167         nan\n",
      " -0.39856879         nan -0.39873013         nan -0.39839031         nan\n",
      " -0.39859033         nan -0.40925603         nan -0.4091632          nan\n",
      " -0.40925603         nan -0.4091632          nan -0.42229776         nan\n",
      " -0.42220226         nan -0.42229776         nan -0.42220226         nan\n",
      " -0.26186529         nan -0.26270812         nan -0.26716125         nan\n",
      " -0.26621837         nan -0.27933219         nan -0.27624829         nan\n",
      " -0.27933219         nan -0.27624829         nan -0.2993453          nan\n",
      " -0.2981378          nan -0.2993453          nan -0.2981378          nan\n",
      " -0.36623297         nan -0.36376161         nan -0.36425156         nan\n",
      " -0.36424497         nan -0.36619958         nan -0.36809207         nan\n",
      " -0.36619958         nan -0.36809207         nan -0.37694267         nan\n",
      " -0.37576428         nan -0.37694267         nan -0.37576428         nan\n",
      " -0.30572004         nan -0.30592268         nan -0.31586664         nan\n",
      " -0.31496885         nan -0.33073432         nan -0.33030049         nan\n",
      " -0.33073432         nan -0.33030049         nan -0.34315929         nan\n",
      " -0.34275167         nan -0.34315929         nan -0.34275167         nan\n",
      " -0.39856879         nan -0.39873013         nan -0.39839031         nan\n",
      " -0.39859033         nan -0.40925603         nan -0.4091632          nan\n",
      " -0.40925603         nan -0.4091632          nan -0.42229776         nan\n",
      " -0.42220226         nan -0.42229776         nan -0.42220226         nan\n",
      " -0.26576813         nan -0.2683807          nan -0.27215969         nan\n",
      " -0.26816926         nan -0.27554911         nan -0.27336357         nan\n",
      " -0.27554911         nan -0.27336357         nan -0.29934129         nan\n",
      " -0.29816267         nan -0.29934129         nan -0.29816267         nan\n",
      " -0.36623297         nan -0.36376161         nan -0.36425156         nan\n",
      " -0.36424497         nan -0.36619958         nan -0.36809207         nan\n",
      " -0.36619958         nan -0.36809207         nan -0.37694267         nan\n",
      " -0.37576428         nan -0.37694267         nan -0.37576428         nan\n",
      " -0.31252924         nan -0.31256271         nan -0.31964997         nan\n",
      " -0.31802327         nan -0.32957624         nan -0.32911672         nan\n",
      " -0.32957624         nan -0.32911672         nan -0.34315929         nan\n",
      " -0.34275167         nan -0.34315929         nan -0.34275167         nan\n",
      " -0.39856879         nan -0.39873013         nan -0.39839031         nan\n",
      " -0.39859033         nan -0.40925603         nan -0.4091632          nan\n",
      " -0.40925603         nan -0.4091632          nan -0.42229776         nan\n",
      " -0.42220226         nan -0.42229776         nan -0.42220226         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid options\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False], \n",
    "    'ccp_alpha': [0.0], \n",
    "    'criterion': ['squared_error'],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'max_features': [0.8, 1.0], \n",
    "    'max_leaf_nodes': [None],\n",
    "    'max_samples': [None],\n",
    "    'min_impurity_decrease': [0.0, 0.01],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_weight_fraction_leaf': [0.0],\n",
    "    'monotonic_cst': [None], \n",
    "    'n_estimators': [50, 100],\n",
    "    'oob_score': [False, True],\n",
    "    'verbose': [0],\n",
    "    'warm_start': [False]\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validatoin\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4, verbose=0)\n",
    "\n",
    "# Fit Grid Search to the training data\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Apply best parameters to Bagging Regressor\n",
    "rf_reg = RandomForestRegressor(**grid_search.best_params_, random_state=42)\n",
    "rf_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions from test features\n",
    "y_pred = rf_reg.predict(X_test_full)\n",
    "\n",
    "# Calculate model evaluation metrics\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_grid = r2_score(y_test_full, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters and Performance from First Grid Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 0.8, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'oob_score': False, 'verbose': 0, 'warm_start': False}\n",
      "Test RMSE: 0.4380\n",
      "Test R-Squared: 0.8214\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Test RMSE: {rmse_grid:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Differences in Metrics from the Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Difference: 0.001142\n",
      "R-Squared Difference: 0.000932\n"
     ]
    }
   ],
   "source": [
    "diff_rmse = rmse_default - rmse_grid\n",
    "diff_r2 =  r2_grid - r2_default\n",
    "\n",
    "print(f\"RMSE Difference: {diff_rmse:.6f}\")\n",
    "print(f\"R-Squared Difference: {diff_r2:.6f}\")\n",
    "\n",
    "#Note: A positive value indicates that Grid Search has improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Pass Grid Search for Random Forest Regressor (1,728 Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid options\n",
    "param_grid = {\n",
    "    'bootstrap': [True], \n",
    "    'ccp_alpha': [0.0], \n",
    "    'criterion': ['squared_error'],\n",
    "    'max_depth': [None, 30, 50],\n",
    "    'max_features': [0.7, 0.8, 0.9, 1.0], \n",
    "    'max_leaf_nodes': [None],\n",
    "    'max_samples': [0.7, 0.8, 0.9, 1.0],\n",
    "    'min_impurity_decrease': [0.0],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_weight_fraction_leaf': [0.0],\n",
    "    'monotonic_cst': [None], \n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'oob_score': [False, True],\n",
    "    'verbose': [0],\n",
    "    'warm_start': [False]\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validatoin\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4, verbose=0)\n",
    "\n",
    "# Fit Grid Search to the training data\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Apply best parameters to Bagging Regressor\n",
    "rf_reg = RandomForestRegressor(**grid_search.best_params_, random_state=42)\n",
    "rf_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions from test features\n",
    "y_pred = rf_reg.predict(X_test_full)\n",
    "\n",
    "# Calculate model evaluation metrics\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_grid = r2_score(y_test_full, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters and Performance from Second Grid Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 0.7, 'max_leaf_nodes': None, 'max_samples': 1.0, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'oob_score': False, 'verbose': 0, 'warm_start': False}\n",
      "Test RMSE: 0.4393\n",
      "Test R-Squared: 0.8203\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Test RMSE: {rmse_grid:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Differences in Metrics from the Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Difference: -0.000229\n",
      "R-Squared Difference: -0.000187\n"
     ]
    }
   ],
   "source": [
    "diff_rmse = rmse_default - rmse_grid\n",
    "diff_r2 =  r2_grid - r2_default\n",
    "\n",
    "print(f\"RMSE Difference: {diff_rmse:.6f}\")\n",
    "print(f\"R-Squared Difference: {diff_r2:.6f}\")\n",
    "\n",
    "#Note: A positive value indicates that Grid Search has improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Pass Grid Search for Random Forest Regressor (240 Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid options\n",
    "param_grid = {\n",
    "    'bootstrap': [True], \n",
    "    'ccp_alpha': [0.0], \n",
    "    'criterion': ['squared_error'],\n",
    "    'max_depth': [None],\n",
    "    'max_features': [0.65, 0.7, 0.75, 0.8], \n",
    "    'max_leaf_nodes': [None],\n",
    "    'max_samples': [0.95, 1.0],\n",
    "    'min_impurity_decrease': [0.0],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [5],\n",
    "    'min_weight_fraction_leaf': [0.0],\n",
    "    'monotonic_cst': [None], \n",
    "    'n_estimators': [150, 175, 200, 225, 250],\n",
    "    'oob_score': [False, True],\n",
    "    'verbose': [0],\n",
    "    'warm_start': [False]\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validatoin\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4, verbose=0)\n",
    "\n",
    "# Fit Grid Search to the training data\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Apply best parameters to Bagging Regressor\n",
    "rf_reg = RandomForestRegressor(**grid_search.best_params_, random_state=42)\n",
    "rf_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions from test features\n",
    "y_pred = rf_reg.predict(X_test_full)\n",
    "\n",
    "# Calculate model evaluation metrics\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_grid = r2_score(y_test_full, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters and Performance from Third Grid Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 0.65, 'max_leaf_nodes': None, 'max_samples': 1.0, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 175, 'oob_score': False, 'verbose': 0, 'warm_start': False}\n",
      "Test RMSE: 0.4454\n",
      "Test R-Squared: 0.8153\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Test RMSE: {rmse_grid:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Differences in Metrics from the Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Difference: -0.006341\n",
      "R-Squared Difference: -0.005222\n"
     ]
    }
   ],
   "source": [
    "diff_rmse = rmse_default - rmse_grid\n",
    "diff_r2 =  r2_grid - r2_default\n",
    "\n",
    "print(f\"RMSE Difference: {diff_rmse:.6f}\")\n",
    "print(f\"R-Squared Difference: {diff_r2:.6f}\")\n",
    "\n",
    "#Note: A positive value indicates that Grid Search has improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Validation RMSE to Test Set RMSE for Model Fit Assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average validation RMSE is 0.4683 units and the test RMSE is 0.4454 units.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The average validation RMSE is {np.sqrt(abs(grid_search.best_score_)):.4f} units and the test RMSE is {rmse_grid:.4f} units.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Despite a slight decrease of 0.005222 in the R-squared value, cross-validation results indicate strong model performance. The small difference between the test RMSE (0.4454) and the average validation RMSE (0.4683) suggests that the model generalizes well.\n",
    "\n",
    "#### We will use the final Grid Search parameters for our Random Forest Regressor model. Although the model has several parameters that risk overfitting (ie. no max depth to the trees, no pruning at all, and no min_impurity_decrease), the minimal difference between validation and test RMSE confirms that there is no significant overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=0.65, max_samples=1.0, min_samples_split=5,\n",
       "                      n_estimators=175, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_features=0.65, max_samples=1.0, min_samples_split=5,\n",
       "                      n_estimators=175, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_features=0.65, max_samples=1.0, min_samples_split=5,\n",
       "                      n_estimators=175, random_state=42)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit random forest regressor using best parameters\n",
    "rf_reg = RandomForestRegressor(**grid_search.best_params_, random_state=42)\n",
    "rf_reg.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Performance Metrics in a DataFrame for Comparison of All Models at the End) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model   RMSE  R-Squared\n",
       "0  Random Forest Regressor  0.445      0.815"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"Random Forest Regressor\"\n",
    "results2 = pd.DataFrame([[model_name, round(rmse_grid,3), round(r2_grid,3)]], columns=[\"Model\", \"RMSE\", \"R-Squared\"])\n",
    "results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Default Parameters for Grid Search Optimization Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor(random_state= 42)\n",
    "print(gb_reg.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check RMSE and R-Squared Values on Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.4471\n",
      "Test R-Squared: 0.8139\n"
     ]
    }
   ],
   "source": [
    "gb_reg.fit(X_train_full, y_train_full)\n",
    "y_pred = gb_reg.predict(X_test_full)\n",
    "\n",
    "rmse_default = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_default = r2_score(y_test_full, y_pred)\n",
    "print(f\"Test RMSE: {rmse_default:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_default:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Pass Grid Search for Gradient Boosting Regressor (5,184 Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': [0.9], \n",
    "    'ccp_alpha': [0.0],  \n",
    "    'criterion': ['friedman_mse'],  \n",
    "    'init': [None],  \n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  \n",
    "    'loss': ['squared_error'],  \n",
    "    'max_depth': [3, 5, 7],  \n",
    "    'max_features': ['sqrt', 'log2', None],  \n",
    "    'max_leaf_nodes': [None],  \n",
    "    'min_impurity_decrease': [0.0],  \n",
    "    'min_samples_leaf': [1, 3, 5],  \n",
    "    'min_samples_split': [2, 5, 7, 10],  \n",
    "    'min_weight_fraction_leaf': [0.0],  \n",
    "    'n_estimators': [50, 100, 200, 250],  \n",
    "    'n_iter_no_change': [None],  \n",
    "    'subsample': [0.8, 0.9, 1.0], \n",
    "    'tol': [0.0001],  \n",
    "    'validation_fraction': [0.1],  \n",
    "    'verbose': [0],  \n",
    "    'warm_start': [False]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validatoin\n",
    "grid_search = GridSearchCV(gb_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4, verbose=0)\n",
    "\n",
    "# Fit Grid Search to the training data\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Apply best parameters to Bagging Regressor\n",
    "gb_reg = GradientBoostingRegressor(**grid_search.best_params_, random_state=42)\n",
    "gb_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions from test features\n",
    "y_pred = gb_reg.predict(X_test_full)\n",
    "\n",
    "# Calculate model evaluation metrics\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_grid = r2_score(y_test_full, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters and Performance from First Grid Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.2, 'loss': 'squared_error', 'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'subsample': 0.8, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "Test RMSE: 0.4461\n",
      "Test R-Squared: 0.8147\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Test RMSE: {rmse_grid:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Differences in Metrics from the Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Difference: 0.000989\n",
      "R-Squared Difference: 0.000823\n"
     ]
    }
   ],
   "source": [
    "diff_rmse = rmse_default - rmse_grid\n",
    "diff_r2 =  r2_grid - r2_default\n",
    "\n",
    "print(f\"RMSE Difference: {diff_rmse:.6f}\")\n",
    "print(f\"R-Squared Difference: {diff_r2:.6f}\")\n",
    "\n",
    "#Note: A positive value indicates that Grid Search has improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Pass Grid Search for Gradient Boosting Regressor (2,160 Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': [0.9], \n",
    "    'ccp_alpha': [0.0],  \n",
    "    'criterion': ['friedman_mse'],  \n",
    "    'init': [None],  \n",
    "    'learning_rate': [0.1, 0.15, 0.2, 0.3],  \n",
    "    'loss': ['squared_error'],  \n",
    "    'max_depth': [2, 3, 4, 5], \n",
    "    'max_features': ['sqrt'],  \n",
    "    'max_leaf_nodes': [None],  \n",
    "    'min_impurity_decrease': [0.0],  \n",
    "    'min_samples_leaf': [4, 5, 6],  \n",
    "    'min_samples_split': [2, 3, 4],  \n",
    "    'min_weight_fraction_leaf': [0.0],  \n",
    "    'n_estimators': [150, 175, 200, 225, 250],  \n",
    "    'n_iter_no_change': [None],  \n",
    "    'subsample': [0.75, 0.8, 0.85], \n",
    "    'tol': [0.0001],  \n",
    "    'validation_fraction': [0.1],  \n",
    "    'verbose': [0],  \n",
    "    'warm_start': [False]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validatoin\n",
    "grid_search = GridSearchCV(gb_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4, verbose=0)\n",
    "\n",
    "# Fit Grid Search to the training data\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Apply best parameters to Bagging Regressor\n",
    "gb_reg = GradientBoostingRegressor(**grid_search.best_params_, random_state=42)\n",
    "gb_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions from test features\n",
    "y_pred = gb_reg.predict(X_test_full)\n",
    "\n",
    "# Calculate model evaluation metrics\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_grid = r2_score(y_test_full, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters and Performance from Second Grid Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.2, 'loss': 'squared_error', 'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'subsample': 0.8, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "Test RMSE: 0.4461\n",
      "Test R-Squared: 0.8147\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Test RMSE: {rmse_grid:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Differences in Metrics from the Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Difference: 0.000989\n",
      "R-Squared Difference: 0.000823\n"
     ]
    }
   ],
   "source": [
    "diff_rmse = rmse_default - rmse_grid\n",
    "diff_r2 =  r2_grid - r2_default\n",
    "\n",
    "print(f\"RMSE Difference: {diff_rmse:.6f}\")\n",
    "print(f\"R-Squared Difference: {diff_r2:.6f}\")\n",
    "\n",
    "#Note: A positive value indicates that Grid Search has improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Pass Grid Search for Gradient Boosting Regressor (360 Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': [0.9], \n",
    "    'ccp_alpha': [0.0, 0.0001, 0.001, 0.01],  \n",
    "    'criterion': ['friedman_mse'],  \n",
    "    'init': [None],  \n",
    "    'learning_rate': [0.15, 0.18, 0.2, 0.22, 0.25],  \n",
    "    'loss': ['squared_error'],  \n",
    "    'max_depth': [3], \n",
    "    'max_features': ['sqrt', None],  \n",
    "    'max_leaf_nodes': [None],  \n",
    "    'min_impurity_decrease': [0.0],  \n",
    "    'min_samples_leaf': [5],  \n",
    "    'min_samples_split': [2],  \n",
    "    'min_weight_fraction_leaf': [0.0],  \n",
    "    'n_estimators': [190, 200, 210],  \n",
    "    'n_iter_no_change': [None],  \n",
    "    'subsample': [0.79, 0.8, 0.81], \n",
    "    'tol': [0.0001],  \n",
    "    'validation_fraction': [0.1],  \n",
    "    'verbose': [0],  \n",
    "    'warm_start': [False]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validatoin\n",
    "grid_search = GridSearchCV(gb_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4, verbose=0)\n",
    "\n",
    "# Fit Grid Search to the training data\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Apply best parameters to Bagging Regressor\n",
    "gb_reg = GradientBoostingRegressor(**grid_search.best_params_, random_state=42)\n",
    "gb_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions from test features\n",
    "y_pred = gb_reg.predict(X_test_full)\n",
    "\n",
    "# Calculate model evaluation metrics\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_test_full, y_pred))\n",
    "r2_grid = r2_score(y_test_full, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters and Performance from Third Grid Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.2, 'loss': 'squared_error', 'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 210, 'n_iter_no_change': None, 'subsample': 0.8, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "Test RMSE: 0.4475\n",
      "Test R-Squared: 0.8135\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Test RMSE: {rmse_grid:.4f}\")\n",
    "print(f\"Test R-Squared: {r2_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Differences in Metrics from the Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Difference: -0.000388\n",
      "R-Squared Difference: -0.000323\n"
     ]
    }
   ],
   "source": [
    "diff_rmse = rmse_default - rmse_grid\n",
    "diff_r2 =  r2_grid - r2_default\n",
    "\n",
    "print(f\"RMSE Difference: {diff_rmse:.6f}\")\n",
    "print(f\"R-Squared Difference: {diff_r2:.6f}\")\n",
    "\n",
    "#Note: A positive value indicates that Grid Search has improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Validation RMSE to Test Set RMSE for Model Fit Assessment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average validation RMSE is 0.4433 units and the test RMSE is 0.4475 units.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The average validation RMSE is {np.sqrt(abs(grid_search.best_score_)):.4f} units and the test RMSE is {rmse_grid:.4f} units.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Despite a slight decrease of 0.000323 in the R-squared value, cross-validation results indicate strong model performance. The small difference between the test RMSE (0.4475) and the average validation RMSE (0.4433) suggests that the model generalizes well.\n",
    "\n",
    "#### We will use the final Grid Search parameters for our Gradient Boosting Regressor model. Although some aspects of this model might be prone to overfitting (ie. no prunning - ccp_alpha = 0.0 and min_samples_split = 2), the minimal difference between validation and test RMSE confirms that there is no significant overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Gradient Boosting Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.2, max_features=&#x27;sqrt&#x27;,\n",
       "                          min_samples_leaf=5, n_estimators=210, random_state=42,\n",
       "                          subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(learning_rate=0.2, max_features=&#x27;sqrt&#x27;,\n",
       "                          min_samples_leaf=5, n_estimators=210, random_state=42,\n",
       "                          subsample=0.8)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.2, max_features='sqrt',\n",
       "                          min_samples_leaf=5, n_estimators=210, random_state=42,\n",
       "                          subsample=0.8)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit bagging regressor using best parameters\n",
    "gb_reg = GradientBoostingRegressor(**grid_search.best_params_, random_state=42)\n",
    "gb_reg.fit(X_train_full, y_train_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Performance Metrics in a DataFrame for Comparison of All Models at the End) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model   RMSE  R-Squared\n",
       "0  Gradient Boosting Regressor  0.448      0.814"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"Gradient Boosting Regressor\"\n",
    "results3 = pd.DataFrame([[model_name, round(rmse_grid,3), round(r2_grid,3)]], columns=[\"Model\", \"RMSE\", \"R-Squared\"])\n",
    "results3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Choosing a Single Model for our UserInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model   RMSE  R-Squared\n",
       "0            Bagging Regressor  0.433      0.826\n",
       "0      Random Forest Regressor  0.445      0.815\n",
       "0  Gradient Boosting Regressor  0.448      0.814"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_models = pd.concat([results1, results2, results3], axis=0)\n",
    "final_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Model Selection\n",
    "\n",
    "While the Bagging Regressor achieved the lowest RMSE and highest R-squared, its performance was very similar to that of the Random Forest Regressor and Gradient Boosting Regressor. To simplify the selection process, I first eliminated the Gradient Boosting Regressor, as it has a higher tendency to overfit, whereas this model needs to generalize well to novel molecules.\n",
    "To ensure strong generalization without overfitting, I prioritized an approach that could identify potential therapeutic agents beyond the historical structural patterns of gepants.\n",
    "\n",
    "There are many shared hyperparameters between the Bagging Regressor and Random Forest Regressor models including:\n",
    "\n",
    "- Use bootstrap sampling to create multiple training subsets\n",
    "- No pruning (ccp_alpha=0)\n",
    "- Use squared error as its splitting metric\n",
    "- No maximum tree depth \n",
    "- No maximum number of leaf nodes \n",
    "- No minimum impurity decrease \n",
    "- No weight fraction constraints \n",
    "- No out-of-bag validation\n",
    "- No warm-start \n",
    "\n",
    "\n",
    "Given these similarities, the main distinction lies in feature selection and tree splitting criteria. The Bagging Regressor uses 100% of the features in every tree and allows splitting with as little as 2 samples per node. While this led to strong test performance, it is concerning that the model may be memorizing patterns in the training data, making it more prone to overfitting.\n",
    "\n",
    "The Random Forest Regressor, on the other hand, randomly selects only 65% of the features per tree and requires at least five samples to split a node. This introduces randomness and prevents over-reliance on any single feature, making the model more likely to generalize well to unseen data. This averaging process allows the model to capture meaningful patterns while avoiding overfitting to specific molecular features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export All Models as a .joblib file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb_reg.joblib']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bagging_reg, 'bagging_reg.joblib') # saves your model variable, named \"model\"\n",
    "joblib.dump(rf_reg, 'rf_reg.joblib') \n",
    "joblib.dump(gb_reg, 'gb_reg.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('Module_2_670')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6f98132c7a593f098ecf3b56dab609f7813301d269f9202a13e4dfaf977ca82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
